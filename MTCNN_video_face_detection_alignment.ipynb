{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "sys.path.append('/users/wangdexun/insightface-deploy/')\n",
    "from face_detection import MtcnnDetector\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import PurePath, Path\n",
    "from umeyama import umeyama\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create MTCNN and its forward pass functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_PATH = '/users/wangdexun/insightface-deploy/face_detection/mtcnn-model/'\n",
    "\n",
    "face_detector=MtcnnDetector(model_folder=WEIGHTS_PATH,\n",
    "                            ctx=mx.gpu(0),\n",
    "                            factor=0.709,\n",
    "                            minsize=30,\n",
    "                            accurate_landmark=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for face detection and alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tar_landmarks(img):\n",
    "    \"\"\"    \n",
    "    img: detected face image\n",
    "    \"\"\"         \n",
    "    ratio_landmarks = [\n",
    "        (0.31339227236234224, 0.3259269274198092),\n",
    "        (0.31075140146108776, 0.7228453709528997),\n",
    "        (0.5523683107816256, 0.5187296867370605),\n",
    "        (0.7752419985257663, 0.37262483743520886),\n",
    "        (0.7759613623985877, 0.6772957581740159)]   \n",
    "        \n",
    "    img_size = img.shape\n",
    "    tar_landmarks = [(int(xy[1]*img_size[1]), \n",
    "                      int(xy[0]*img_size[0])) for xy in ratio_landmarks]\n",
    "    return tar_landmarks\n",
    "\n",
    "def landmarks_match_mtcnn(src_img, src_landmarks, tar_landmarks, img_size): \n",
    "    \"\"\"\n",
    "    umeyama(src, dst, estimate_scale)\n",
    "    landmarks coord. for umeyama should be (width, height) or (y, x)\n",
    "    \"\"\"\n",
    "    src_size = src_img.shape\n",
    "    M = umeyama(np.array(src_landmarks), np.array(tar_landmarks), True)[0:2] \n",
    "    result = cv2.warpAffine(src_img, M, img_size, borderMode=cv2.BORDER_REPLICATE) \n",
    "    return result\n",
    "\n",
    "def process_mtcnn_bbox(bbox, im_shape):\n",
    "    \"\"\"Here we process the bbox coord. to a square bbox.\n",
    "    避免后续resize使五官变形\n",
    "    \"\"\"\n",
    "    x0, y0, x1, y1 = bbox\n",
    "    h, w = int(y1 - y0), int(x1 - x0)\n",
    "    radius = int((w+h)/2/2) # todo: int(max(w,h)/2)\n",
    "    center_x,center_y = int((x1+x0)/2),int((y1+y0)/2)\n",
    "    new_x0 = max(0,center_x-radius)\n",
    "    new_y0 = max(0,center_y-radius)\n",
    "    new_x1 = min(im_shape[1],center_x+radius)\n",
    "    new_y1 = min(im_shape[0],center_y+radius)\n",
    "    bbox = (new_x0, new_y0, new_x1, new_y1)\n",
    "    return bbox\n",
    "\n",
    "def process_image(img_path,save_dir): \n",
    "    global face_detector\n",
    "    \n",
    "    # run detector\n",
    "    input_img = cv2.imread(img_path)\n",
    "    results = face_detector.detect_face(input_img)\n",
    "    if results is None:\n",
    "        return\n",
    "    \n",
    "    total_boxes = results[0]\n",
    "    points = results[1]\n",
    "    \n",
    "    max_index=0\n",
    "    if len(total_boxes)>1:\n",
    "        bbox_area=(total_boxes[:,2]-total_boxes[:,0])*(total_boxes[:,3]-total_boxes[:,1])\n",
    "        max_index=np.argmax(bbox_area)\n",
    "    \n",
    "    bbox=total_boxes[max_index][:4]\n",
    "    landmark=points[max_index].reshape((2,5)).T\n",
    "    \n",
    "    face_bbox=process_mtcnn_bbox(bbox,input_img.shape)\n",
    "    x0,y0,x1,y1=face_bbox\n",
    "    det_face_img = input_img[y0:y1,x0:x1,:]\n",
    "    \n",
    "    # get src/tar landmarks\n",
    "    src_landmarks = landmark\n",
    "    tar_landmarks = get_tar_landmarks(det_face_img)\n",
    "    \n",
    "    # align detected face\n",
    "    h, w = det_face_img.shape[:2]\n",
    "    aligned_det_face_img = landmarks_match_mtcnn(input_img, src_landmarks, tar_landmarks,(w,h))\n",
    "    \n",
    "    # binary mask on the eyes  \n",
    "    bm = np.zeros_like(input_img)\n",
    "    bm[int(src_landmarks[0][1]-h/15):int(src_landmarks[0][1]+h/15),\n",
    "       int(src_landmarks[0][0]-w/8):int(src_landmarks[0][0]+w/8),:] = 255\n",
    "    bm[int(src_landmarks[1][1]-h/15):int(src_landmarks[1][1]+h/15),\n",
    "       int(src_landmarks[1][0]-w/8):int(src_landmarks[1][0]+w/8),:] = 255\n",
    "    bm = landmarks_match_mtcnn(bm, src_landmarks, tar_landmarks,(w,h))\n",
    "    \n",
    "    # save\n",
    "    _,img_name=os.path.split(img_path)\n",
    "\n",
    "    fname = os.path.join(save_dir,'aligned_faces',img_name)\n",
    "    os.makedirs(os.path.dirname(fname),exist_ok=True)\n",
    "    cv2.imwrite(fname, aligned_det_face_img)\n",
    "\n",
    "    fname = os.path.join(save_dir,'raw_faces',img_name)\n",
    "    os.makedirs(os.path.dirname(fname),exist_ok=True)\n",
    "    cv2.imwrite(fname, det_face_img)\n",
    "     \n",
    "    fname = os.path.join(save_dir,'binary_masks_eyes',img_name)\n",
    "    os.makedirs(os.path.dirname(fname),exist_ok=True)\n",
    "    cv2.imwrite(fname, bm)\n",
    "    \n",
    "def detect_align_face(data_dir,save_dir):\n",
    "    images=glob.glob(os.path.join(data_dir,'*.*g'))\n",
    "    os.makedirs(save_dir,exist_ok=True)\n",
    "    with tqdm(total=len(images),desc='Processing images') as pbar:\n",
    "        with Pool(processes=12) as p:\n",
    "            worker=partial(process_image,save_dir=save_dir)\n",
    "            for _ in p.imap(worker,images):\n",
    "                pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_align_face('../data/wdx/original/','./faces/wdx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_align_face('../data/ccj/original/','./faces/ccj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_align_face('../data/wxb/original/','./faces/wxb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_align_face('../data/leo/original/','./faces/leo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot examples\n",
    "data_dir='./faces/ccj/'\n",
    "images=os.listdir(os.path.join(data_dir,'raw_faces'))\n",
    "print('Load {} images in total'.format(len(images)))\n",
    "for i in np.random.choice(images,10,replace=False):\n",
    "    dir_names=['raw_faces','aligned_faces','binary_masks_eyes']\n",
    "    fig,axes=plt.subplots(1,4,figsize=(16,9))\n",
    "    raw_img=cv2.imread(os.path.join(data_dir,dir_names[0],i))\n",
    "    axes[0].imshow(raw_img[...,::-1])\n",
    "    aligned_img=cv2.imread(os.path.join(data_dir,dir_names[1],i))\n",
    "    axes[1].imshow(aligned_img[...,::-1])\n",
    "    bm_img=cv2.imread(os.path.join(data_dir,dir_names[2],i))\n",
    "    axes[2].imshow(bm_img[...,::-1])\n",
    "    mask_img=np.multiply(aligned_img,bm_img/255)\n",
    "    mask_img=mask_img.astype(np.uint8)\n",
    "    axes[3].imshow(mask_img[...,::-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_src_landmarks(x0, y0, x1, y1, pnts):\n",
    "#     \"\"\"\n",
    "#     x0, x1, y0, y1: (smoothed) bbox coord.\n",
    "#     pnts: landmarks predicted by MTCNN\n",
    "#     \"\"\"    \n",
    "#     src_landmarks = [(int(pnts[i][0]-x0), \n",
    "#                       int(pnts[i][1]-y0)) for i in range(5)]\n",
    "#     return src_landmarks\n",
    "\n",
    "# def get_tar_landmarks(img):\n",
    "#     \"\"\"    \n",
    "#     img: detected face image\n",
    "#     \"\"\"         \n",
    "#     ratio_landmarks = [\n",
    "#         (0.31339227236234224, 0.3259269274198092),\n",
    "#         (0.31075140146108776, 0.7228453709528997),\n",
    "#         (0.5523683107816256, 0.5187296867370605),\n",
    "#         (0.7752419985257663, 0.37262483743520886),\n",
    "#         (0.7759613623985877, 0.6772957581740159)]   \n",
    "        \n",
    "#     img_size = img.shape\n",
    "#     tar_landmarks = [(int(xy[1]*img_size[1]), \n",
    "#                       int(xy[0]*img_size[0])) for xy in ratio_landmarks]\n",
    "#     return tar_landmarks\n",
    "\n",
    "# def landmarks_match_mtcnn(src_img, src_landmarks, tar_landmarks): \n",
    "#     \"\"\"\n",
    "#     umeyama(src, dst, estimate_scale)\n",
    "#     landmarks coord. for umeyama should be (width, height) or (y, x)\n",
    "#     \"\"\"\n",
    "#     src_size = src_img.shape\n",
    "#     M = umeyama(np.array(src_landmarks), np.array(tar_landmarks), True)[0:2] \n",
    "#     result = cv2.warpAffine(src_img, M, (src_size[1], src_size[0]), borderMode=cv2.BORDER_REPLICATE) \n",
    "#     return result\n",
    "\n",
    "# def process_mtcnn_bbox(bbox, im_shape):\n",
    "#     \"\"\"Here we process the bbox coord. to a square bbox.\n",
    "#     避免后续resize使五官变形\n",
    "#     \"\"\"\n",
    "#     x0, y0, x1, y1 = bbox\n",
    "#     h, w = int(y1 - y0), int(x1 - x0)\n",
    "#     radius = int((w+h)/2/2) # todo: int(max(w,h)/2)\n",
    "#     center_x,center_y = int((x1+x0)/2),int((y1+y0)/2)\n",
    "#     new_x0 = max(0,center_x-radius)\n",
    "#     new_y0 = max(0,center_y-radius)\n",
    "#     new_x1 = min(im_shape[1],center_x+radius)\n",
    "#     new_y1 = min(im_shape[0],center_y+radius)\n",
    "#     bbox = (new_x0, new_y0, new_x1, new_y1)\n",
    "#     return bbox\n",
    "\n",
    "# def process_image(img_path,save_dir): \n",
    "#     global face_detector\n",
    "    \n",
    "#     # run detector\n",
    "#     input_img=cv2.imread(img_path)\n",
    "#     results = face_detector.detect_face(input_img)\n",
    "#     if results is None:\n",
    "#         return\n",
    "    \n",
    "#     total_boxes = results[0]\n",
    "#     points = results[1]\n",
    "    \n",
    "#     max_index=0\n",
    "#     if len(total_boxes)>1:\n",
    "#         bbox_area=(total_boxes[:,2]-total_boxes[:,0])*(total_boxes[:,3]-total_boxes[:,1])\n",
    "#         max_index=np.argmax(bbox_area)\n",
    "    \n",
    "#     bbox=total_boxes[max_index][:4]\n",
    "#     landmark=points[max_index].reshape((2,5)).T\n",
    "    \n",
    "#     face_bbox=process_mtcnn_bbox(bbox,input_img.shape)\n",
    "#     x0,y0,x1,y1=face_bbox\n",
    "#     det_face_img = input_img[y0:y1,x0:x1,:]\n",
    "    \n",
    "#     # get src/tar landmarks\n",
    "#     src_landmarks = get_src_landmarks(x0, y0, x1, y1, landmark)\n",
    "#     tar_landmarks = get_tar_landmarks(det_face_img)\n",
    "    \n",
    "#     # align detected face\n",
    "#     aligned_det_face_img = landmarks_match_mtcnn(det_face_img, \n",
    "#                                                  src_landmarks, \n",
    "#                                                  tar_landmarks)\n",
    "#     # binary mask on the eyes  \n",
    "#     bm = np.zeros_like(det_face_img)\n",
    "#     h, w = bm.shape[:2]\n",
    "#     bm[int(src_landmarks[0][1]-h/15):int(src_landmarks[0][1]+h/15),\n",
    "#        int(src_landmarks[0][0]-w/8):int(src_landmarks[0][0]+w/8),:] = 255\n",
    "#     bm[int(src_landmarks[1][1]-h/15):int(src_landmarks[1][1]+h/15),\n",
    "#        int(src_landmarks[1][0]-w/8):int(src_landmarks[1][0]+w/8),:] = 255\n",
    "#     bm = landmarks_match_mtcnn(bm, src_landmarks, tar_landmarks)\n",
    "    \n",
    "#     # save\n",
    "#     _,img_name=os.path.split(img_path)\n",
    "\n",
    "#     fname = os.path.join(save_dir,'aligned_faces',img_name)\n",
    "#     os.makedirs(os.path.dirname(fname),exist_ok=True)\n",
    "#     cv2.imwrite(fname, aligned_det_face_img)\n",
    "\n",
    "#     fname = os.path.join(save_dir,'raw_faces',img_name)\n",
    "#     os.makedirs(os.path.dirname(fname),exist_ok=True)\n",
    "#     cv2.imwrite(fname, det_face_img)\n",
    "     \n",
    "#     fname = os.path.join(save_dir,'binary_masks_eyes',img_name)\n",
    "#     os.makedirs(os.path.dirname(fname),exist_ok=True)\n",
    "#     cv2.imwrite(fname, bm)\n",
    "    \n",
    "# def detect_align_face(data_dir,save_dir):\n",
    "#     images=glob.glob(os.path.join(data_dir,'*.*g'))\n",
    "#     os.makedirs(save_dir,exist_ok=True)\n",
    "#     with tqdm(total=len(images),desc='Processing images') as pbar:\n",
    "#         with Pool(processes=12) as p:\n",
    "#             worker=partial(process_image,save_dir=save_dir)\n",
    "#             for _ in p.imap(worker,images):\n",
    "#                 pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start face detection\n",
    "\n",
    "Default input video filename: `INPUT_VIDEO.mp4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global frames\n",
    "frames = 0\n",
    "\n",
    "# configuration\n",
    "save_interval = 6 # perform face detection every {save_interval} frames\n",
    "fn_input_video = \"../data/wyf/wyf5.mp4\"\n",
    "\n",
    "output = './faces/videos/dummy.mp4'\n",
    "clip1 = VideoFileClip(fn_input_video)\n",
    "clip = clip1.fl_image(process_video)#.subclip(0,3) #NOTE: this function expects color images!!\n",
    "clip.write_videofile(output, audio=False)\n",
    "clip1.reader.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
